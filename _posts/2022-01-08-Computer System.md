---
layout:     post
title:      按下运行那一刻发生了什么(一)
subtitle:   关于计算机底层的故事
date:       2022-01-08
author:     hdbdjdbm
header-img: img/post-bg-coffee.jpeg
catalog: true
tags:
    - 计算机底层
---

# 写在开篇
本篇试读人士：只上过大学生计算机基础，其他一无所知。

所有计算机系统都有相似的硬件和软件组件，它们又执行着相似的功能。
此篇文章主题是深入了解这些组件是如何工作的以及这些组件是如何影响程序的正确性和性能的。

踏上了未曾设想的读后感道路。以防有人也会踏上这条缺德的不归路，以下内容均为教材原内容，无增加或者修改。

# 从跟踪 hello 程序的生命周期开始

```c
#include <stdio.h>

int main()
{
    printf("hello, world\n");
    return O;
}
```

**信息就是位+上下文** 

hello程序的生命周期是从一个源程序(或者说源文件)开始的，即程序员通过编辑器创建并保存的文本文件，文件名是 hello.c。源程序实际上就是一个由值 0 和 1 组成的位(又称为比特)序列，8个位被组织成一组，称为字节。每个字节表示程序中的某些文本字符。大部分的现代计算机系统都使用 ASCII 标准来表示文本字符，这种方式实际上就是用一个唯一的单字节大小的整数值来表示每个字符。
![image-1](https://pic.imgdb.cn/item/61d68be42ab3f51d91084258.png)

>二进制

每个文本行都是以一个看不见的换行符来结束的，它所对应的整数值为 10。像 hello.c 这样只只由ASCII 字符构成的文件称为文本文件，所有其他文件都称为二进制文件。(其他文件指的是？)

*tips*
--
系统中所有的信息，包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。

**程序被其他程序翻译成不同的格式**

hello 程序的生命周期是从一个高级 C 语言程序开始的，因为这种形式能够被人读懂。然而，为了在系统上运行 hello.c 程序，每条 C 语句都必须被其他程序转化为一系列的低级机器语言指令。然后这些指令按照一种称为可执行目标程序的格式打好包，并以二进制磁盘文件的形式存放起来。目标程序也称为可执行目标文件。

在 Unix 系统上，从源文件到目标文件的转化是由编译器驱动程序完成的
```unix
linux> gcc -o hello hello.c
```
GCC 编译器驱动程序读取源程序文件 hello.c并把它翻译成一个可执行目标文件 hello。这个翻译过程可分为四个阶段完成。执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统（compilation system)

![image-2](https://pic.imgdb.cn/item/61d68e2d2ab3f51d910a2fc7.png)

>本人os: 抽烟.jpg 感谢前人，真心的


**处理器读并解释储存在内存中的指令** 

此刻，hello.c 源程序已经被编译系统翻译成了可执行目标文件 hello, 并被存放在磁盘上。要想在 Unix 系统上运行该可执行文件，我们将它的文件名输人到称为 shell 的应用程序中：
```shell
linux> ./hello
hello, world
linux>
```
shell 是一个命令行解释器，它输出一个提示符，等待输人一个命令行，然后执行这个命令。如果该命令行的第一个单词不是一个内置的 shell 命令，那么 shell 就会假设这是一个可执行文件的名字，它将加载并运行这个文件。所以在此例中，shell 将加载并运行hello 程序，然后等待程序终止。hello 程序在屏幕上输出它的消息，然后终止。shell随后输出一个提示符，等待下一个输人的命令行。

为了更好解释内部发生了什么，先了解一个典型系统的硬件组织。这张图是近期 Intel 系统产品族的模型。

![image-2](https://pic.imgdb.cn/item/61d6a4aa2ab3f51d911c9577.png)

* **总线** ： 贯穿整个系统的是一组电子管道，称作总线，它携带信息字节并负责在各个部件间传递。**通常总线被设计成传送定长的字节块，也就是字(word)。字中的字节数(即字长)是一个基本的系统参数**，各个系统中都不尽相同。现在的大多数机器字长要么是 4 个字节(32位)， 要么是 8 个字节(64 位)。

* **I/O(输入/输出)** ： I/O 设备是系统与外部世界的联系通道。我们的示例系统包括四个 I/O 设备：作为用户输入的键盘和鼠标，作为用户输出的显示器，以及用于长期存储数据和程序的磁盘驱动器(简单地说就是磁盘)。**每个 I/O 设备都通过一个控制器或适配器与 I/O 总线相连**。控制器是 I/O 设备本身或者系统的主印制电路板(通常称作主板)上的芯片组。而适配器则是一块插在主板插槽上的卡。但无论如何它们的功能都是在 I/O 总线和 I/O 设备之间传递信息。

* **主存** ： 主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存取存储器(DRAM)芯片组成的。**从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址(数组索引)， 这些地址是从零开始的**。一般来说，组成程序的每条机器指令都由不同数量的字节构成。与 C 程序变量相对应的数据项的大小是根据类型变化的。比如，在运行 Linux 的 X86-64 机器上，short 类型的数据需要 2 个字节，int 和 float 类型需要 4 个字节，而 long 和 double 类型需要 8 个宇节。


* **处理器** ： 中央处理单元(CPU), 简称处理器，是解释(或执行)存储在主存中指令的**引擎**。处理器的核心是一个大小为一个字的**存储设备(或寄存器)， 称为程序计数器(PC)**。在任何时刻，PC 都指向主存中的某条机器语言指令(即含有该条指令的地址)。**处理器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新 PC使其指向下一条指令**，而这条指令并不一定和在内存中刚刚执行的指令相邻。这样的简单操作并不多，它们围绕着主存、寄存器文件(register file)和算术/逻辑单元(ALU)进行。**寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字**。ALU 计算新的数据和地址值。下面是一些简单操作的例子，CPU 在指令的要求下可能会执行这些操作。
> 加载：从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容。

> 存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原
来的内容。

> 操作：把两个寄存器的内容复制到 ALU, ALU 对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容。

> 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器（PC)中，以覆盖PC 中原来的值。

**运行 hello 程序** 

![image-4](https://pic.imgdb.cn/item/61d6aa752ab3f51d91211cbd.png)

初始时，shell 程序执行它的指令，等待我们输人一个命令。当我们在键盘上输人字符串/hello后，shell 程序将字符逐一**读入寄存器，再把它存放到内存中**。

当我们在键盘上敲回车键时，shell 程序就知道我们已经结束了命令的输人。然后shell 执行一系列指令来加载可执行的 hello 文件，**这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存**。数据包括最终会被输出的字符串Hello,world。

**利用直接存储器存取(DMA)技术，数据可以不通过处理器而直接从磁盘到达主存。**

![image-5](https://pic.imgdb.cn/item/61d6ab8b2ab3f51d9121f901.png)

**一旦目标文件 hello 中的代码和数据被加载到主存，处理器就开始执行 hello 程序的 main 程序中的机器语言指令。这些指令将Hello, world字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。**

![image-6](https://pic.imgdb.cn/item/61d6abed2ab3f51d91223c87.png)

**高速缓存**

这个简单的示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方挪到另一个地方。hello 程序的机器指令最初是存放在**磁盘**上，当程序加载时，它们被复制到**主存**；当处理器运行程序时，指令又从主存复制到**处理器**。相似地，**数据串**开始时在磁盘上，然后被复制到主存，最后从主存上复制到显示设备。从程序员的角度来看，这些复制就是开销，减慢了程序“真正”的工作。因此，系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。


一个典型的寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，**处理器从寄存器文件中读数据比从主存中读取几乎要快 100 倍**。更麻烦的是，随着这些年**半导体**技术的进步，这种处理器与主存之间的差距还在持续增大。**加快处理器的运行速度比加快主存的运行速度要容易和便宜得多**。

针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，**称为高速缓存存储器(cache memory, 简称为 cache 或高速缓存)，作为暂时的集结区域，存放处理器近期可能会需要的信息。**


位于处理器芯片上的 L1 高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快。一个容量为数十万到数百万字节的更大的 L2 高速缓存通过一条特殊的总线连接到处理器。进程访问 L2 高速缓存的时间要比访问 L1 高速缓存的时间长 5 倍，但是这仍然比访问主存的时间快 5-10 倍。L1 和 L2 高速缓存是用一种叫做静态随机访问存储器(SRAM)的硬件技术实现的。通过让高速缓存里存放可能经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。

![image-7](https://pic.imgdb.cn/item/61d6ad2d2ab3f51d9123373f.png)


**存储设备形成层次结构**

每个计算机系统中的存储设备都被组织成了一个存储器层次结构，在这个层次结构中，**从上至下，设备的访问速度越来越慢、容量越来越大，并且每字节的造价也越来越便宜。** 寄存器文件在层次结构中位于最顶部。

![image-8](https://pic.imgdb.cn/item/61d6ae042ab3f51d9123f19b.png)

存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。因此，寄存器文件就是 L1 的高速缓存，L1 是 L2 的高速缓存，L2 是 L3 的高速缓存，L3 是主存的高速缓存，而主存又是磁盘的高速缓存。在某些具有分布式文件系统的网络系统中，本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存。

**操作系统管理硬件**

我们可以把操作系统看成是应用程序和硬件之间插人的一层软件。所有应用程序对硬件的操作尝试都必须通过操作系统。

操作系统有两个基本功能：
(1)防止硬件被失控的应用程序滥用
(2)向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。文件是对 I/O 设备的抽象表示，虚拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象表示。

![image-8](https://pic.imgdb.cn/item/61d6b16e2ab3f51d9127023d.png)


* **进程**

程序看上去是独占地使用处理器、主存和 I/O设备。处理器看上去就像在不间断地一条接一条地执行程序中的指令，即该程序的代码和数据是系统内存中唯一的对象。这些假象是通过进程的概念来实现的，进程是计算机科学中最重要和最成功的概念之一。


**进程是操作系统对一个正在运行的程序的一种抽象**。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而并发运行，则是说一个进程的指令和另一个进程的指令是交错执行的。在大多数系统中，**需要运行的进程数是多于可以运行它们的CPU个数的。** 传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论是在单核还是多核系统中，一个 CPU 看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。**操作系统实现这种交错执行的机制称为上下文切换。**



操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，包括许多信息，比如 PC 和寄存器文件的当前值，以及主存的内容。**在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。新进程就会从它上次停止的地方开始。** 


示例场景中有两个并发的进程：shell 进程和 hello 进程。最开始，只有 shell 进程在运行，即等待命令行上的输人。**当我们让它运行 hello 程序时，shell 通过调用一个专门的函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统保存 shell 进程的上下文，创建一个新的 hello 进程及其上下文，然后将控制权传给新的 hello 进程。hello 进程终止后，操作系统恢复 shell 进程的上下文，并将控制权传回给它,shell 进程会继续等待下一个命令行输人。**

![image-9](https://pic.imgdb.cn/item/61d6b37d2ab3f51d9128cbc1.png)

**从一个进程到另一个进程的转换是由操作系统内核(kernel)管理的。内核是操作系统代码常驻主存的部分。** 当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的系统调用(system call)指令，**将控制权传递给内核**。然后内核执行被请求的操作并返回应用程序。**注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。** 

* **线程**

尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，**一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型**，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。当有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法。


* **虚拟内存**

虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。在 Linux 中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。请注意，图中的地址是从下往上增大的。
![image-6](https://pic.imgdb.cn/item/61d6b46a2ab3f51d9129b10e.png)

>**程序代码和数据**。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和C全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。

>**堆**。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小，与此不同，**当调用像 malloc 和 free 这样的 C 标准库函数时，堆可以在运行时动态地扩展和收缩**。

> **共享库**。大约在地址空间的中间部分是一块用来存放像 C 标准库和数学库这样的共享库的代码和数据的区域。

> **栈**。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。

> **内核虚拟内存**。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，它们必须调用内核来执行这些操作。

* **文件**

文件就是字节序列，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。系统中的所有输人输出都是通过使用一小组称为 Unix I/O 的系统函数调用读写文件来实现的。

**系统之间利用网络通信**

从一台主机复制信息到另外一台主机已经成为计算机系统最重要的用途之一。比如，像电子邮件、即时通信、万维网等这样的应用都是基于网络复制信息的功能。

我们可以使用熟悉的 telnet 应用在一个远程主机上运行 hello 程序。假设用本地主机上的 telnet 客户端连接远程主机上的 telnet 服务器。在我们登录到远程主机并运行 shell 后，远端的 shell 就在等待接收输入命令。此后在远端运行 hello 程序。


![image-4](https://pic.imgdb.cn/item/61d7bc312ab3f51d91d23d43.png)


**并发(concurrency)与并行（parallelism)**

并发是一个通用的概念，指一个同时具有多个活动的系统；而并行指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。在此，我们按照系统层次结构中由高到低的顺序重点强调三个层次。

**1 线程级并发**

构建在进程这个抽象之上，我们能够设计出同时有多个程序执行的系统，这就导致了并发。使用线程，我们甚至能够在一个进程中执行多个控制流。传统意义上，这种并发执行只是模拟出来的，是通过使一台计算机在它正在执行的进程间快速切换来实现的。当构建一个由单操作系统内核控制的多处理器组成的系统时，我们就得到了一个多处理器系统。

![image-7](https://pic.imgdb.cn/item/61d7bde52ab3f51d91d34853.png)

微处理器芯片有 4 个 CPU 核，每个核都有自己的 L1 和
L2 高速缓存，其中的 L1 高速缓存分为两个部分。一个保存最近取到的指令，另一个存放数据。这些核共享更高层次的高速缓存，以及到主存的接口。

**超线程，有时称为同时多线程(simultaneous multi-threading), 是一项允许一个CPU执行多个控制流的技术**。它涉及 CPU 某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份，比如执行浮点算术运算的单元。常规的处理器需要大约20 000 个时钟周期做不同线程间的转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。**这使得 CPU 能够更好地利用它的处理资源**。比如，假设一个线程必须等到某些数据被装载到高速缓存中，那 CPU 就可以继续去执行另一个线程。


**2 指令级并行**

在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。

**3 单指令、多数据并行**

在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。例如，较新几代的 Intel 和AMD 处理器都具有并行地对 8 对单精度浮点数(C 数据类型 float)做加法的指令。


**抽象**

抽象的使用是计算机科学中最为重要的概念之一。例如，为一组函数规定一个简单的应用程序接口(AH)就是一个很好的编程习惯，程序员无须了解它内部的工作便可以使用这些代码。不同的编程语言提供不同形式和等级的抽象支持。

![image-8](https://pic.imgdb.cn/item/61d7bff42ab3f51d91d49250.png)

在处理器里，指令集架构提供了对实际处理器硬件的抽象。使用这个抽象，机器代码程序表现得就好像运行在一个一次只执行一条指令的处理器上。底层的硬件远比抽象描述的要复杂精细，它并行地执行多条指令，但又总是与那个简单有序的模型保持一致。在学习操作系统时，我们介绍了三个抽象：文件是对 I/O 设备的抽象，虚拟内存是对程序存储器的抽象，而进程是对一个正在运行的程序的抽象。虚拟机，它提供对整个计算机的抽象，包括操作系统、处理器和程序。


小结
--
计算机系统是由硬件和系统软件组成的，它们共同协作以运行应用程序。计算机内部的信息被表示为一组组的位，它们依据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，开始时是ASCII 文本，然后被编译器和链接器翻译成二进制可执行文件。

处理器读取并解释存放在主存里的二进制指令。因为计算机花费了大量的时间在内存、I/O 设备和CPU 寄存器之间复制数据，所以将系统中的存储设备划分成层次结构层的硬件高速缓存存储器、DRAM 主存和磁盘存储器。在层次模型中，位于更高层的存储设备比低层的存储设备要更快，单位比特造价也更高。层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。通过理解和运用这种存储层次结构的知识，程序员可以优化 C 程序的性能。

操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的抽象：1)文件是对 I/O 设备的抽攀；2)虚拟内存是对主存和磁盘的抽象；3)进程是处理器、主存和 I/O 设备的抽象。
最后，网络提供了计算机系统之间通信的手段。从特殊系统的角度来看，网络就是一种 I/O 设备。










# 程序结构和执行

## 信息的表示和处理

**十六进制表示法**

大多数计算机使用 8 位的块，或者**字节(byte), 作为最小的可寻址的内存单位**，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为虚拟内存。内存的每个字节都由一个唯一的数字来标识，称为它的地址。每个程序对象可以简单地视为一个字节块，而程序本身就是一个字节序列。

一个字节由 8 位组成。在二进制表示法中，它的值域是 00000000 - 11111111。二进制表示法太冗长，而十进制表示法与位模式的互相转化很麻烦。替代的方法是，以 16 为基数，或者叫做十六进制(hexadecimal)数，来表示位模式。

十六进制(简写为'Hex'，使用数字0-9,以及字符A-F表示 16 个可能的值。用十六进制书写，一个字节的值域为 $00_{16}$ - $FF_{16}$

![image-9](https://pic.imgdb.cn/item/61d7f0412ab3f51d91fb258e.png)

在 C 语言中，以 Ox 或 0X 开头的数字常量被认为是十六进制的值,字符既可以大写也可以小写。例如，我们可以将数字 FA1D37B16写作 0XFA1D37B。大小写可以混合。

**字数据大小**

每台计算机都有一个字长(word size), **指明指针数据的标称大小(nominal size)**。因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。也就是说，对于一个字长为u位的机器而言，虚拟地址的范围为 0 - $2^u-1$，程序最多访问$2^u$ 个字节。

**寻址和字节顺序**

在几乎所有的机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。例如，假设一个类型为 int 的变量 x 的地址为 0x100, 也就是说，地址表达式的值为 0x100那么，(假设数据类型 int ,为 32 位表示) x 的 4 个字节将被存储在内存的 0x100、0x101、0x102 和 0x103 位置。


排列表示一个对象的字节有两个通用的规则。按照从最高有效字节到最低有效工字节的顺序存储。前一种规则:最低有效字节在最前面的方式，称为小端法(little endian)。后一种规则最高有效字节在最前面的方式，称为大端法(big endian)。

假设变量 x 的类型为 int 位于地址 0x100 处，它的十六进制值为 0x01234567。地址范围 0x100 - 0x103 的字节顺序依赖于机器的类型。

![image-1](https://pic.imgdb.cn/item/61d7f4832ab3f51d91ff316f.png)

对于大多数应用程序员来说，其机器所使用的字节顺序是完全不可见的。无论为哪种类型的机器所编译的程序都会得到同样的结果。不过有时候，字节顺序会成为问题。

首先是在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时，接收程序会发现，字里的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成网络标准，而接收方机器则将网络标准转换为它的内部表示。

第二种情况是，当阅读表示整数数据的字节序列时字节顺序也很重要。当阅读像小端法机器生成的机器级程序表示时，经常会将字节按照相反的顺序显示。书写字节序列的自然方式是最低位字节在左边，而最高位字节在右边，这正好和通常书写数字时最高有效位在左边，最低有效位在右边的方式相反。例子见P30。

字节顺序变得重要的第三种情况是当编写规避正常的类型系统的程序时。



**表示字符串**

C 语言中字符串被编码为一个以 null(其值为 0)字符结尾的字符数组。每个字符都由某个标准编码来表示，最常见的是 ASCII 字符码。


**表示代码**

不同的机器类型使用不同的且不兼容的指令和编码方式。即使是完全一样的进程，运行在不同的操作系统上也会有不同的编码规则，因此二进制代码是不兼容的。

**布尔代数**

* 布尔运算〜对应于逻辑运算 NOT
* 布尔运算&对应于逻辑运算 AND
* 布尔运算丨对应于逻辑运算 0R
* 布尔运算 ^ 对应于逻辑运算 异或(EXCLUSIVE-OR) ：当 P 或者 Q 为真但不同时为真时，我们说 P^Q = 1


**C语言中的位级运算**

C 语言的一个很有用的特性就是它支持按位布尔运算。确定一个位级表达式的结果最好的方法，就是将十六进制的参数扩展成二进制表示并执行二进制运算，然后再转换回十六进制。

**C语言中的逻辑运算**

C 语言还提供了一组逻辑运算符 || 、 &&和！。逻辑运算很容易和位级运算相混淆，但是它们的功能是完全不同的。逻辑运算认为所有非零的参数都表示 TRUE。而参数 0 表示 FALSE。它们返回 1 或者 0, 分别表示结果为 TRUE 或者为 FALSE。

**C语言中的移位运算**

C 语言还提供了一组移位运算，向左或者向右移动位模式。C 表达式 << k 会生成一个值。也就是说，x 询左移动 k 位，丢弃最高的 k 位，并在右端补 k 个 0。有一个相应的右移运算 x >> k。但是它的行为有点微妙。一般而言，机器支持两种形式的右移：逻辑右移和算术右移。逻辑右移在左端补k个 0, 算术右移是在左端补 k 个最高有效位的值。(比如操作数的最高位是 1，填充的值就是 1，例如对[01110000],[1001001]算术右移结果分别为[00000110],[11111001]。实际上，几乎所有的编译器/机器组合都对有符号数使用算术右移。与 C 相比，Java 对于如何进行右移有明确的定义。表达是 x>>k 会将 x 算术右移 k 个
位置，而 x>>>k 会对 x 做逻辑右移。加法(和减法)的优先级比移位运算要高。所以当你拿不准的时候，请加上括号！



## 整数表示

用位来编码整数的两种不同的方式：一种只能表示非负数，而另
一种能够表示负数、零和正数。

**无符号数的编码**

我们用一个函数 $B2U_\omega$(Binary to Unsigned的缩写，长度为 w)来表示。

$B2U_4([0001])$ = 1

**补码编码**

对于许多应用，我们还希望表示负数值。最常见的有符号数的计算机表示方式就是补码（two’s-complement) 形式。在这个定义中，将字的**最高有效位解释为负权**(negative weight).我们用函数$B2T_\omega$ (Binary to Two’s-complement 的缩写，长度为 w)来表示。

$B2U_4([0001])$ = 1
$B2U_4([1011])$ = -5


tips
--
第一，补码的范围是不对称的：$|TMin|$=|TMax|+1，也就是说，$TMin$ 没有与之对应的正数。

第二，最大的无符号数值刚好比补码的最大值的两倍大一点： $UMax_\omega$ = $2TMax_\omega$+1。补码表示中所有表示负数的位模式在无符号表示中都变成了正数。

C 语言标准并没有要求要用补码形式来表示有符号整数，但是几乎所有的机器都是这么做的。程序员如果希望代码具有最大可移植性，能够在所有可能的机器上运行，那么除了那些范围之外，我们不应该假设任何可表示的数值范围。

**有符号数和无符号数之间的转换**

总结一下，我们考虑无符号与补码表示之间互相转换的结果。对于在范围
$TMax_\omega$之内的值 x 而言,数字有相同的无符号和补码表示。对于这个范围以外的数值，转换需要加上或者减去 $2^\omega$


tips
--

有符号数到无符号数的隐式强制类型转换导致了某些非直观的行为。而这些非直观的特性经常导致程序错误，并且这种包含隐式强制类型转换的细微差别的错误很难被发现。因为这种强制类型转换是在代码中没有明确指示的情况下发生的。

避免这类错误的一种方法就是绝不使用无符号数。实际上，除了 C 以外很少有语言支持无符号整数。很明显，这些语言的设计者认为它们带来的
麻烦要比益处多得多。

当我们想要把字仅仅看做是位的集合而没有任何数字意义时，无符号数值是非常有用的。例如，往一个字中放入描述各种布尔条件的标记(flag)时，就是这样。地址自然地就是无符号的，所以系统程序员发现无符号类型是很有帮助的。当实现模运算和多精度运算的数学包时，数字是由字的数组来表示的，无符号值也会非常有用。

## 整数运算

[具体可以参考:整数的运算](https://zhuanlan.zhihu.com/p/37520131)


说一个算术运算溢出，是指完整的整数结果不能放到数据类型的字长限制中去。

![image-10](https://pic.imgdb.cn/item/61d80fda2ab3f51d911c807d.png)

*此处略去了很多计算细节

由于整数乘法比移位和加法的代价要大得多，许多 C 语言编译器试图以移位、加法和减法的组合来消除很多整数乘以常数的情况。

正如我们看到的，计算机执行的“整数”运算实际上是一种模运算形式。表示数字的有限字长限制了可能的值的取值范围，结果运算可能溢出。我们还看到，补码表示提供了一种既能表示负数也能表示正数的灵活方法，同时使用了与执行无符号算术相同的位级实现，这些运算包括像加法、减法、乘法，甚至除法，无论运算数是以无符号形式还是以补码形式表示的，都有完全一样或者非常类似的位级行为。



## 浮点数

[具体可以参考：浮点数的运算](https://zhuanlan.zhihu.com/p/37524880)

IEEE 浮点标准用 $V=(-1)^s x M x 2^E$的形式来表示一个数：
>符号(sign) s 决定这数是负数(s=l)还是正数(s=0)，而对于数值 0 的符号位解释作为特殊情况处理。

>尾数(significand) M 是一个二进制小数，它的范围是 1 ~ $2 - \epsilon$或者是 0 ~ $1 - \epsilon$

>阶码(exponent) E的作用是对浮点数加权，这个权重是 2 的 E次幂(可能是负数)。将浮点数的位表示划分为三个字段，分别对这些值进行编码：
1. 一个单独的符号位 s 直接编码符号1
2. K位的阶码字段 $exp=e_{k-1}...e_1e_0"$编码阶码E
3. n位小数字段 $frac=f_{n-1}...f_1f_0$编码尾数 M, 但是编码出来的值也依赖于阶码字段的值是否等于 0。

![image-11](https://pic.imgdb.cn/item/61d813ca2ab3f51d911fe081.png)


假如我们将上图中的值的位表达式解释为无符号整数，它们就是按升序排列的，就像它们表示的浮点数一样。这不是偶然的，IEEE格式如此设计就是为了浮点数能够使用整数排序函数来进行排序。



插播
![image-12](https://pic.imgdb.cn/item/61d814492ab3f51d91203bf5.png)



总结
--
计算机将信息编码为位(比特)， 通常组织成字节序列。有不同的编码方式用来表示整数、实数和字符串。不同的计算机模型在编码数字和多字节数据中的字节顺序时使用不同的约定。

C 语言的设计可以包容多种不同字长和数字编码的实现。64 位字长的机器逐渐普及，并正在取代统治市场长达 30 多年的 32 位机器。由于 64 位机器也可以运行为 32 位机器编译的程序，我们的重点就放在区分 32 位和 64 位程序，而不是机器本身。64 位程序的优势是可以突破 32 位程序具有的 4GB 地址限制。

**大多数机器对整数使用补码编码，而对浮点数使用 IEEE 标准 754 编码**。在位级上理解这些编码，并且理解算术运算的数学特性，对于想使编写的程序能在全部数值范围上正确运算的程序员来说，是很重要的。

在相同长度的无符号和有符号整数之间进行强制类型转换时，大多数 C 语言实现遵循的原则是底层的位模式不变。在补码机器上，对于一个 w 位的值，这种行为是由函数$T2U_\omega$和$U2T_\omega$,来描述的。C 语言隐式的强制类型转换会出现许多程序员无法预计的结果，常常导致程序错误。

由于编码的长度有限，与传统整数和实数运算相比，计算机运算具有非常不同的属性。当超出表示范围时，有限长度能够引起数值溢出。当浮点数非常接近于 0.0, 从而转换成零时，也会下溢。

和大多数其他程序语言一样，C 语言实现的有限整数运算和真实的整数运算相比，有一些特殊的属性。例如，由于溢出，表达式 x*x 能够得出负数。。但是，无符号数和补码的运算都满足整数运算的许多其他属性，包括结合律、交换律和分配律。这就允许编译器做很多的优化。例如，用（x«3)-x 取代表达式时，我们就利用了结合律、交换律和分配律的属性，还利用了移位和乘以 2 的幂之间的关系。

我们已经看到了几种使用位级运算和算术运算组合的聪明方法。这些位模式有助于掩码运算。这种模式能够通过 C 表达式(i«k)-i生成，利用的是这样一个属性，即我们想要的位模式的数值为$2^k - 1$。

浮点表示通过将数字编码为 $xX2^y$ 的形式来近似地表示实数。最常见的浮点表示方式是由 IEEE 标准 754 定义的。它提供了几种不同的精度，最常见的是单精度(32 位)和双精度(64 位)。 IEEE 浮点也能
够表示特殊值例如正无穷等。

必须非常小心地使用浮点运算，因为浮点运算只有有限的范围和精度，而且并不遵守普遍的算术属性，比如结合性。


# 历史小故事

* C编程语言的起源

* GNU项目

* Unix、Posix和标准 Unix 规范

* Amdahl 定律

该定律的主要思想是，当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。所以Amdahl 定律的主要观点是: 要想显著加速整个系统，必须提升全系统中相当大的部分的速度。

* 声明指针

对于任何数据类型T，声明
T *P;
表明 p 是一个指针变量，指向一个类型为 了的对象。例如，
char *p;
就将一个指针声明为指向一个 char 类型的对象。

* 端的起源

战争开始是由于以下的原因：我们大家都认为，吃鸡蛋前，原始的方法是打破鸡蛋较大的一端，可是当今皇帝的祖父小时候吃鸡蛋，一次按古法打鸡蛋时碰巧将一个手指弄破了，因此他的父亲，当时的皇帝，就下了一道敕令，命令全体臣民吃鸡蛋时打破鸡蛋较小的一端，违令者重罚。老百姓们对这项命令极为反感。历史告诉我们，由此曾发生过六次叛乱，其中一个皇帝送了命，另一个丢了王位。这些叛乱大多都是由 Blefuscu 的国王大臣们煽动起来的。叛乱平息后，流亡的人总是逃到那个帝国去寻救避难。据估计，先后几次有 11000人情愿受死也不肯去打破鸡蛋较小的一端。关于这一争端，曾出版过几百本大部著作，不过大端派的书一直是受禁的，法律也规定该派的任何人不得做官。”（此段译文摘自网上蒋剑锋译的《格利佛游记》第一卷第 4 章。在他那个时代，Swift 是在讽刺英国（Lilliput)和法国（Blefuscu)之间持续的冲突。Danny Cohen, 一位网络协议的早期开创者，第一次使用这两个术语来指代字节顺序, 后来这个术语被广泛接纳了。

* 摩尔定律(Moore’s Law)

* 文字编码的Unicode标准

* 有符号数的其他表示方法(反码与原码)

* IEEE
电气和电子工程师协会（IEEE, 读做eye-triple-ee 是一个包括所有电子和计算机技术的专业团体。它出版刊物，举办会议，并且建立委员会来定义标准，内容涉及从电力传输到软件工程。另一个 IEEE 标准的例子是无线网络的 802.11 标准。